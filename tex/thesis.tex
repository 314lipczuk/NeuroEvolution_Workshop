\documentclass{article}
\usepackage{graphicx} % Required for inserting images

% table stuff
 \usepackage[normalem]{ulem}
 \useunder{\uline}{\ul}{}
 \usepackage[normalem]{ulem}
 \useunder{\uline}{\ul}{}
 \usepackage[normalem]{ulem}
 \useunder{\uline}{\ul}{}
 \usepackage[normalem]{ulem}
 \useunder{\uline}{\ul}{}
 \usepackage{float}

\title{NanoNeat}
\author{Przemys≈Çaw Pilipczuk}
\date{December 2023}

\begin{document}

\maketitle

\tableofcontents
\section{Introduction}
\subsection{Abstract}
In this work I have implemented a fully functional NeuroEvolution of Augumenting Topologies (NEAT) algorithm 
with a focus on simplicity and readibility. The generic core algorithm is ~400 lines of Python code, and to use it in a specific problem requires about ~70 
more. I would argue that because of that it is a good starting point for anyone interested in learning about NEAT, as it is easy to understand and
easy to modify. The implementation was tested on 4 problems: XOR, Cartpole, Acrobot and BipedalWalker. 
good resource for learning about NEAT.
\subsection{Keywords}
Neuroevolution, NEAT, Evolutionary Algorithms, Machine Learning, Artificial Intelligence, Didactic Implementation
\section{Related work}
todo[idk, write about original paper here? or maybe about other implemetations?]
\section{Methodology}
    \subsection{Problems used to test the implementation}
        \subsubsection{XOR}
        Xor problem is a simple problem used mostly to test if the algorithm can start generating structure. 
        This is because XOR function is non linearly separable - it cannot be solved by the simple topology that neat starts with.
        To solve it, the algorithm needs to evolve a hidden layer. 
        This problem is also used to test if the algorithm can generate minimal structure - the original paper 
        todo[CITATION] states that the algoritm can solve the problem with 1 node in the hidden layer (However,
        it does require that the starting topology has an additional input node designated
        as bias, connected straight to the output). This requirement is not presented as a builtin configuration variant for this specific problem , as
        it is trivial to add it using basic configuration change (add 1 more input that always returns "1", and add a function that 
        hooks start of the population to set its connection weight to the output as 1).
        \subsubsection{Cartpole}
        Cartpole is a problem taken from Farama Foundation's Gymnasium library. It is a classic control problem, 
        where an agent tries to balance a pole on a cart. The agent's observation space consists of cart's 
        position, velocity, angle of the pole and its angular velocity. The agent can move the cart left or right.
        This problem is a test of the implementation's ability to solve a basic real-world problem, but contrary 
        to the xor problem, its model is subjected to multiple sequential runs,
        with its fitness being judged based on its cumulative performance across these runs. This means, that
        recurrent connections can potentially be used.
        \subsubsection{Acrobot}
        Acrobot is a similar problem to the cartpole, with a slightly bigger state space. The problem consists
        of a two-link system, one of its ends fixed to a certain position. All of the joints are allowed to rotate,
        abd the agent is given control over an actuated joint between the two links. Its goal is to swing the
        end of the free link over given height (while starting from a hanging position). 
        THis problem also is evaluated as a single evaluation session, being subjected to multiple sequential runs,
        with its fitness being judged based on its cumulative performance across these runs.
        \subsubsection{BipedalWalker}
        BipedalWalker is the hardest problem used in this work. It is a problem taken from Farama Foundation's
        Gymnasium library. The agent tries to control a bipedal robot and make it walk to the end of the map, while
        making its movements energy-efficient. The observation space is significantly bigger than in previous problems,
        consisting of 24 values. The action space somewhat similar, but due to the problem specifics, requiring a 
        much more precise control. 
    \subsection{Implementation details}
        \subsubsection{Core algorithm}
        The core algorithm if NEAT is implemented in ~400 lines of Python in model.py
        The base for a single agent is a class called Genome. It contains a list of nodes and a list of connections for this particular 
        specimen, as well as a fitness value. Nodes and Connections have their own respectively named classes, both of which are accessing
        their Genomes' config object to get information about their ids and innovation numbers. Genome also controls the mutation process of itself,
        having separate methods for mutations of nodes, connections, and weights. Genome's config is a shared object between all genomes, and it is 
        given to it by a Population object during its initialization. Population is a class that controls the whole algorithm. It is responsible for
        maintaining a list of genomes, list of species, and maintaining a coherent state between all the mutations of genomes and changes in specie set.
        It is also responsible for the toplevel loop, that runs the algorithm for a given number of generations. The single loop looks like this:
        \begin{enumerate}
            \item Divide the population into Species
            \item Calculate fitness of each individual genome
            \item Check for exit condition
            \item Calculate adjusted fitness of each individual genome
            \item Calculate offspring count for each specie
            \item Create new generation by crossover and mutation of selected genomes and species
            \item Repeat
        \end{enumerate}
        The Specie class is responsible for dealing with the speciation process and calculating relevant statistics for each (such as adjusted fitness or 
        generation without improvement count). 
        \subsubsection{Configuration}
        Population object is initialized with a Config object, which is a main way to configure algorithm. It is a simple object with a set of fields
        and a couple of methods. Most of the fields have default values, and are not required to be set manually by the user. The few fields that are
        mandatory are: 
        \begin{itemize}
            \item activation - the function used for activation
            \item input\_size - the number of input nodes
            \item output\_size - the number of output nodes
            \item experiment\_path - a path to where the experiment results will be saved
            \item fitness\_function - a function that takes a genome and returns its fitness
        \end{itemize}
        \begin{table}[H]
            \resizebox{\columnwidth}{!}{%
            \begin{tabular}{|l|l|l|}
            \hline
            \textbf{Variable name}               & \textbf{Default value} & \textbf{Description}                                                                                                                              \\ \hline
            c1                                   & 1                      & \begin{tabular}[c]{@{}l@{}}Modifier for excess genes count when calculating\\  distance between genomes\end{tabular}                              \\ \hline
            c2                                   & 1                      & \begin{tabular}[c]{@{}l@{}}Modifier for disjoint genes count when calculating\\  distance between genomes\end{tabular}                            \\ \hline
            c3                                   & 0.8                    & \begin{tabular}[c]{@{}l@{}}Modifier for weight differences when calculating\\  distance between genomes\end{tabular}                              \\ \hline
            meta                                 & \{\}                   & A dictionary to store problem-specific variables.                                                                                                      \\ \hline
            print\_generation                    &                        & \begin{tabular}[c]{@{}l@{}}A user-defined function for printing generation \\ during training\end{tabular}                                        \\ \hline
            every\_generation                    &                        & \begin{tabular}[c]{@{}l@{}}A function being executed after every generation.\\  Useful for saving information about learning\end{tabular}         \\ \hline
            after\_finished                      &                        & \begin{tabular}[c]{@{}l@{}}A function being executed after a problem\\  is finished\end{tabular}                                                  \\ \hline
            chance\_mutate\_weight               & 0.8                    & \begin{tabular}[c]{@{}l@{}}A chance for mutating weight during mutation\\  process\end{tabular}                                                   \\ \hline
            chance\_of\_20\_proc\_weight\_change & 0.9                    & Chance for a 20\% chance of weight value                                                                                                          \\ \hline
            chance\_of\_randomize\_weight        & 0.1                    & \begin{tabular}[c]{@{}l@{}}Chance for a completely new randomized value\\  for a given weight\end{tabular}                                        \\ \hline
            chance\_add\_connection              & 0.05                   & A chance to add a connection during mutation                                                                                                      \\ \hline
            chance\_add\_node                    & 0.05                   & A chance to add a node during mutation                                                                                                            \\ \hline
            tries\_to\_make\_connection          & 20                     & \begin{tabular}[c]{@{}l@{}}How many times system will try to find a valid\\  connection to make\end{tabular}                                      \\ \hline
            chance\_to\_reactivate\_connection   & 0.25                   & A chance to reactivate a disabled connection                                                                                                      \\ \hline
            allow\_recurremt                     & True                   & Allow forming recurrent connection                                                                                                                \\ \hline
            population\_size                     & 50                     & A size of population                                                                                                                              \\ \hline
            specie\_target                       & 4                      & A amount of species that system is trying to achieve                                                                                              \\ \hline
            max\_iterations                      & 600                    & \begin{tabular}[c]{@{}l@{}}A max amount of generation that system\\  is permitted to run for\end{tabular}                                         \\ \hline
            threshold\_step\_size                & 0.3                    & \begin{tabular}[c]{@{}l@{}}An amount that will be added or deleted to\\  threshold if specie size is higher or \\ lower than desired\end{tabular} \\ \hline
            problem\_fitness\_threshold          & 390                    & \begin{tabular}[c]{@{}l@{}}A threshold for fitness that will signify\\ that a genome has finished\\ successfully if exceeded\end{tabular}         \\ \hline
            top\_proc\_to\_reproduce             & 0.2                    & \begin{tabular}[c]{@{}l@{}}A percent of top genomes in every species' \\ that is enabled to reproduce\end{tabular}                                \\ \hline
            cross\_specie\_reproduction          & True                   & Can organisms pick partners out of their species                                                                                                  \\ \hline
            cross\_specie\_weight\_modifier      & 0.3                    & \begin{tabular}[c]{@{}l@{}}Modifier applied to chance of out-of-specie\\  reproduction\end{tabular}                                               \\ \hline
            enable\_elitism                      & True                   & \begin{tabular}[c]{@{}l@{}}Can best organisms in given generation be\\  passed to next generation\end{tabular}                                    \\ \hline
            elitism\_percentage                  & 0.05                   & \begin{tabular}[c]{@{}l@{}}How much of best organism from certain\\  generation can be passed to the next\end{tabular}                            \\ \hline
            dynamic\_threshold                   & True                   & \begin{tabular}[c]{@{}l@{}}A dynamic threshold tries to change\\  threshold to keep the specie size to\\  the given target\end{tabular}           \\ \hline
            initial\_threshold                   & 3                      & \begin{tabular}[c]{@{}l@{}}An initial threshold value for calculating\\  distance between two\\  genomes during speciation\end{tabular}           \\ \hline
            \end{tabular}%
            }
        \end{table}
        The fields presented here are all generic over the problem the algorithm is trying to solve. If a problem requires a specific configuration,
        (like a name of environment in gymnasium, or an offset for calculating fitness) it is stored in the meta field. This implementation was chosen
        to make sure users cannot accidentally overwrite an iternal field of the Config object, and also to provide a clear boundary between NEAT config 
        and problem-specific config, ensuring a more generic structure.
        \subsubsection{Problem-specific adjustments}
        \begin{itemize}
            \item XOR - This problem is given a custom activation function - a steepened sigmoid function.
            This is because in this problem we don't care about exact value of the output, but rather if it is closer to 0 or 1.
            The fitness function from origial NEAT paper todo[citation], namely $$(4 - \sum_{n=1}^{4}c_n-o_n)^2$$
            where $c_n$ is the correct output and $o_n$ is the output of the network, for the problem's case number $n$.
            Recurrent connections are disabled.
            \item Cartpole - Here the configuration's meta field is used to store the name of the environment in gymnasium. That 
            variable is then used during Population initialization to create an environment. Fitness function then accesses that 
            environment to evaluate the genome.  
            \item Acrobot - Similarly to previous problem, configuration here utilizes meta field for Gymnasium's environment name. 
            Other than that, the configuration is standard with only mandatory fields being set.
            \item BipedalWalker - This problem required the most adjustments to the configuration. First of all, the fitness function 
            was tasked with offsetting the reward given by the environment, as its broad range of possible values was causing
            problems during adjusted fitness calculation, and therefore affecting mating pool selection. The fitness function was 
            programmed to cut minimum environment fitness value to a -100, and then offset that by 100 to make sure the fitness was always in range
            of 0-400. This fixed the problem of adjusted fitness calculation, but also forced us to increase the fitness threshold 
            for the problem by a 100. For clarity and coherent experience, custom printing function was used to print the 'environment' fitness
            for the problem, as it is more intuitive. During the testing of this setup, it was discovered that 
            the agent would often get stuck in an unrecoverable position and slow down the simulation by having to wait for the upper limit of time
            for the task to be reached. To fix this behavior, an additional variable was introduced to the model evaluation loop. It
            tracked the amount of timesteps since last improvement in the environment, and terminated the simulation if that number exceeded 
            a certain constant amount. This helped to increase the speed of learning, while not affecting the quality of the model in any way.
            Walker also needed its own activation function, as the baseline sigmoid function was not able to provide values in range [-1, 1].
            \end{itemize}
\section{Experimental results}
\begin{itemize}
    \item XOR
    The xor problem on default configuration described before was tested with a population of 50, 100 tries and generation threshold of 300. The solution was found in 87 trials, and the mean
    generations it took to find the solution in those was 120.5, with standard deviation of 63.6 generations.
    \item Acrobot 
    Acrobot problem on default configuration solved the problem in all 1000 trials, with average
    generations being 4.45, standard deviation being 3.5. We also measured mean and standard deviation
    for the size of the structure that solved the problem. Average problem was solved in average of 8.95 nodes and 17.07
    connections, with respective standard deviations being 1.09 and 2.38.
    \item Cartpole
    Cartpole problem on default configuration solved the problem in all 1000 trials, with average
    generations being 2.77, standard deviation being 1.91. We also measured mean and standard deviation
    for the size of the structure that solved the problem. Average problem was solved in average of 5.06 nodes and 4.12 
    connections, with respective standard deviations being 0.31 and 0.66.

\end{itemize}
\section{Conclusions}
From our results, there can be many conclusions. The problems do not constitute a linear progression of 
difficulty, and we can broadly say, that Acrobot and Cartpole problems were not complex enough for the network,
as a lot of the times they can be solved without evolving much of structure. They show, however that algorithm is capable
of exploring its current topology. 
The case of bipedalwalker is a curious one. The model can reliably learn to walk to the end of the map (corresponding
to this is fitness of about ~150-200). It cannot however finish the course with a cumulative fitness required by the
environment. How is that possible? The environment in bipedalwalker has total fitness requirement of 300, divided
into small chunks given to an agent by moving forward. However, environment also keeps track of the movement made
by the agent, and reduces reward based on the 'energy-efficiency' of its movements. In this situation agent 
gets terminated by the environment (has walked to the end of the map), but doesn't have enough fitness to be 
qualified as a win. 
TODO- Xor vs xor2
[here write conclusions about results of experiments]
\section{Future work}
\section{Bibliography}
\end{document}